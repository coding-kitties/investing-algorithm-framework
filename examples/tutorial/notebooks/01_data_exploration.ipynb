{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Data exploration\n",
    "\n",
    "This notebook demonstrates how to download and prepare cryptocurrency data for backtesting using the Investing Algorithm Framework.\n",
    "\n",
    "This wil showcase the following steps:\n",
    "- Define constants and parameters\n",
    "- Setup folder structure for data storage and results\n",
    "- Generate rolling backtest windows\n",
    "- Download historical OHLCV data for specified assets and time frames\n",
    "- Check data completeness and fill missing timestamps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Constants\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from datetime import datetime, timezone\n",
    "from investing_algorithm_framework import BacktestDateRange, \\\n",
    "    generate_rolling_backtest_windows\n",
    "\n",
    "data_storage_path = Path.cwd().parent / \"data\"\n",
    "backtest_results_dir = Path.cwd().parent / \"backtest_results\"\n",
    "reports_dir = Path.cwd().parent / \"reports\"\n",
    "figures_dir = reports_dir / \"figures\"\n",
    "\n",
    "backtest_window_date_range = BacktestDateRange(\n",
    "    start_date=datetime(2022, 1, 1, tzinfo=timezone.utc),\n",
    "    end_date=datetime(2025, 12, 30, tzinfo=timezone.utc)\n",
    ")\n",
    "MARKET = \"BITVAVO\"\n",
    "\n",
    "in_sample_assets = [\"BTC\", \"ETH\", \"ADA\", \"SOL\", \"DOT\"]\n",
    "out_sample_assets = [\"XRP\", \"LTC\", \"BCH\"]\n",
    "time_frames = [\"2h\", \"4h\", \"1d\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Setup folder structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# create all required directories\n",
    "if not os.path.exists(data_storage_path):\n",
    "    os.makedirs(data_storage_path)\n",
    "\n",
    "if not os.path.exists(backtest_results_dir):\n",
    "    os.makedirs(backtest_results_dir)\n",
    "\n",
    "if not os.path.exists(reports_dir):\n",
    "    os.makedirs(reports_dir)\n",
    "\n",
    "if not os.path.exists(figures_dir):\n",
    "    os.makedirs(figures_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Backtest windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rolling_backtest_windows = generate_rolling_backtest_windows(\n",
    "    start_date=backtest_window_date_range.start_date,\n",
    "    end_date=backtest_window_date_range.end_date,\n",
    "    train_days=365,\n",
    "    test_days=180,\n",
    "    gap_days=30,\n",
    "    step_days=90,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## Data downloading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from investing_algorithm_framework import download_v2, TimeFrame, tqdm\n",
    "in_sample_data = {}\n",
    "out_sample_data = {}\n",
    "\n",
    "for symbol in in_sample_assets:\n",
    "    symbol_pair = f\"{symbol}/EUR\"\n",
    "\n",
    "    for time_frame in tqdm(time_frames, desc=f\"Downloading data for {symbol_pair} {time_frames}\"):\n",
    "        if symbol not in in_sample_data:\n",
    "            in_sample_data[symbol] = {}\n",
    "\n",
    "        result = download_v2(\n",
    "            symbol=symbol_pair,\n",
    "            market=MARKET,\n",
    "            time_frame=time_frame,\n",
    "            data_type=\"ohlcv\",\n",
    "            start_date=backtest_window_date_range.start_date,\n",
    "            end_date=backtest_window_date_range.end_date,\n",
    "            save=True,\n",
    "            storage_path=str(data_storage_path)\n",
    "        )\n",
    "        in_sample_data[symbol][time_frame] = {\n",
    "            \"data\": result.data,\n",
    "            \"path\": result.path\n",
    "        }\n",
    "        first_date = result.data.index[0]\n",
    "\n",
    "        if first_date > backtest_window_date_range.start_date:\n",
    "            print(f\"Warning: Data for {symbol_pair} starts on {first_date} which is after the requested start date of {backtest_window_date_range.start_date}.\")\n",
    "\n",
    "\n",
    "for symbol in out_sample_assets:\n",
    "    symbol_pair = f\"{symbol}/EUR\"\n",
    "\n",
    "    for time_frame in tqdm(time_frames, desc=f\"Downloading data for {symbol_pair} {time_frames}\"):\n",
    "        if symbol not in out_sample_data:\n",
    "            out_sample_data[symbol] = {}\n",
    "\n",
    "        result = download_v2(\n",
    "            symbol=symbol_pair,\n",
    "            market=MARKET,\n",
    "            time_frame=time_frame,\n",
    "            data_type=\"ohlcv\",\n",
    "            start_date=backtest_window_date_range.start_date,\n",
    "            end_date=backtest_window_date_range.end_date,\n",
    "            save=True,\n",
    "            storage_path=str(data_storage_path)\n",
    "        )\n",
    "        out_sample_data[symbol][time_frame] = {\n",
    "            \"data\": result.data,\n",
    "            \"path\": result.path\n",
    "        }\n",
    "        first_date = result.data.index[0]\n",
    "\n",
    "        if first_date > backtest_window_date_range.start_date:\n",
    "            print(f\"Warning: Data for {symbol_pair} starts on {first_date} which is after the requested start date of {backtest_window_date_range.start_date}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## Check data completeness and fill missing timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from investing_algorithm_framework import fill_missing_timeseries_data, tqdm, get_missing_timeseries_data_entries\n",
    "\n",
    "for symbol, time_frames_dict in tqdm(in_sample_data.items(), desc=\"Checking in-sample data\"):\n",
    "    for time_frame, entry in time_frames_dict.items():\n",
    "        data = entry[\"data\"]\n",
    "        file_path = entry[\"path\"]\n",
    "        missing_dates = get_missing_timeseries_data_entries(data)\n",
    "\n",
    "        if len(missing_dates) > 0:\n",
    "            print(f\"Filling {len(missing_dates)} missing dates for {symbol} {time_frame}\")\n",
    "            fill_missing_timeseries_data(\n",
    "                data,\n",
    "                missing_dates=missing_dates,\n",
    "                save_to_file=True,\n",
    "                file_path=str(file_path)\n",
    "            )\n",
    "\n",
    "for symbol, time_frames_dict in tqdm(out_sample_data.items(), desc=\"Checking out-sample data\"):\n",
    "    for time_frame, entry in time_frames_dict.items():\n",
    "        data = entry[\"data\"]\n",
    "        file_path = entry[\"path\"]\n",
    "        missing_dates = get_missing_timeseries_data_entries(data)\n",
    "\n",
    "        if len(missing_dates) > 0:\n",
    "            print(f\"Filling {len(missing_dates)} missing dates for {symbol} {time_frame}\")\n",
    "            fill_missing_timeseries_data(\n",
    "                data,\n",
    "                missing_dates=missing_dates,\n",
    "                save_to_file=True,\n",
    "                file_path=str(file_path)\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## Analysis on the Backtest Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import Dict, Tuple\n",
    "import pandas as pd\n",
    "from investing_algorithm_framework import create_markdown_table, BacktestDateRange\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "\n",
    "def show_backtest_windows_analysis(\n",
    "    data: Dict[str, Tuple[BacktestDateRange, pd.DataFrame]],\n",
    "):\n",
    "    \"\"\"\n",
    "    Show analysis of backtest windows. Each entry in `data` should map\n",
    "    a label to a tuple of (date_range, ohlcv_dataframe).\n",
    "\n",
    "    Args:\n",
    "        data (Dict[str, Tuple[BacktestDateRange, pd.DataFrame]]): Mapping\n",
    "            of labels (backtest window identifiers) to\n",
    "            (date_range, ohlcv_dataframe)\n",
    "\n",
    "    Returns:\n",
    "        List[Dict]: List of detailed analysis dictionaries for each window\n",
    "    \"\"\"\n",
    "    summary_data = []\n",
    "    detailed_analysis = []\n",
    "\n",
    "    for key, (date_range, df) in data.items():\n",
    "        sliced_data = df[date_range.start_date:date_range.end_date].copy()\n",
    "\n",
    "        if sliced_data.empty:\n",
    "            continue\n",
    "\n",
    "        # Calculate comprehensive metrics\n",
    "        sliced_data['returns'] = sliced_data['Close'].pct_change().dropna()\n",
    "\n",
    "        start_price = sliced_data['Close'].iloc[0]\n",
    "        end_price = sliced_data['Close'].iloc[-1]\n",
    "        total_return = (end_price / start_price - 1) * 100\n",
    "\n",
    "        daily_returns = sliced_data['returns'] * 100\n",
    "        volatility = daily_returns.std() * np.sqrt(365)\n",
    "        mean_daily_return = daily_returns.mean()\n",
    "        sharpe_ratio = (mean_daily_return * 365) / volatility if volatility > 0 else 0\n",
    "\n",
    "        # Drawdown analysis\n",
    "        rolling_max = sliced_data['Close'].cummax()\n",
    "        drawdown = (sliced_data['Close'] / rolling_max - 1) * 100\n",
    "        max_drawdown = drawdown.min()\n",
    "\n",
    "        # Volatility regimes\n",
    "        high_vol_days = (daily_returns.abs() > daily_returns.abs().quantile(0.8)).sum()\n",
    "        low_vol_days = (daily_returns.abs() < daily_returns.abs().quantile(0.2)).sum()\n",
    "\n",
    "        # Trend analysis (count of data points, not calendar days)\n",
    "        up_periods = (daily_returns > 0).sum()\n",
    "        down_periods = (daily_returns < 0).sum()\n",
    "        total_periods = len(sliced_data)\n",
    "\n",
    "        # Duration in calendar days\n",
    "        duration_days = (date_range.end_date - date_range.start_date).days\n",
    "        start_date_str = date_range.start_date.strftime('%Y-%m-%d')\n",
    "        end_date_str = date_range.end_date.strftime('%Y-%m-%d')\n",
    "\n",
    "        summary_data.append({\n",
    "            \"window\": key,\n",
    "            \"date_range\": f\"{start_date_str} to {end_date_str}\",\n",
    "            \"days\": str(duration_days),\n",
    "            \"avg_daily_return\": f\"{mean_daily_return:.3f}%\",\n",
    "            \"cumulative_return\": f\"{total_return:.2f}%\",\n",
    "            \"volatility_ann\": f\"{volatility:.2f}%\",\n",
    "            \"sharpe_ratio\": f\"{sharpe_ratio:.2f}\",\n",
    "            \"max_drawdown\": f\"{max_drawdown:.2f}%\",\n",
    "            \"up_periods\": f\"{up_periods} ({up_periods/total_periods*100:.1f}%)\",\n",
    "            \"down_periods\": f\"{down_periods} ({down_periods/total_periods*100:.1f}%)\",\n",
    "            \"high_vol_periods\": f\"{high_vol_days} ({high_vol_days/total_periods*100:.1f}%)\",\n",
    "            \"low_vol_periods\": f\"{low_vol_days} ({low_vol_days/total_periods*100:.1f}%)\"\n",
    "        })\n",
    "\n",
    "        # Detailed analysis for each period\n",
    "        detailed_analysis.append({\n",
    "            'name': key,\n",
    "            'total_return': total_return,\n",
    "            'volatility': volatility,\n",
    "            'sharpe_ratio': sharpe_ratio,\n",
    "            'max_drawdown': max_drawdown,\n",
    "            'up_periods': up_periods,\n",
    "            'down_periods': down_periods,\n",
    "            'high_vol_periods': high_vol_days,\n",
    "            'low_vol_periods': low_vol_days,\n",
    "            'duration_days': duration_days,\n",
    "            'total_periods': total_periods,\n",
    "            'mean_daily_return': mean_daily_return,\n",
    "            'start_price': start_price,\n",
    "            'end_price': end_price\n",
    "        })\n",
    "\n",
    "    # Create and display the markdown table\n",
    "    table = create_markdown_table(summary_data)\n",
    "    display(Markdown(table))\n",
    "\n",
    "    return detailed_analysis\n",
    "\n",
    "\n",
    "# Prepare data for analysis - use BTC as reference asset\n",
    "btc_data = in_sample_data[\"BTC\"][\"2h\"][\"data\"]\n",
    "\n",
    "# Create analysis data dictionary from rolling backtest windows\n",
    "analysis_data = {}\n",
    "for i, window in enumerate(rolling_backtest_windows):\n",
    "    train_range = window[\"train_range\"]\n",
    "    analysis_data[f\"Window {i+1} (Train)\"] = (train_range, btc_data)\n",
    "\n",
    "    if \"test_range\" in window:\n",
    "        test_range = window[\"test_range\"]\n",
    "        analysis_data[f\"Window {i+1} (Test)\"] = (test_range, btc_data)\n",
    "\n",
    "# Show the analysis\n",
    "detailed_results = show_backtest_windows_analysis(\n",
    "    data=analysis_data,\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
